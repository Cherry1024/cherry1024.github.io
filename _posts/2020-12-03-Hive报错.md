---
layout:     post
title:      Apache Hive 执行HQL语句报错
subtitle:   Hive执行HQL语句的时候出现了java heap不足的报错
date:       2020-12-03
author:     CY
header-img: img/post-bg-food3.jpg
catalog: 	 true
mathjax:       true
tags:
    - Big Data
    - Hive
---



### # 故障描述

hive执行`select count` HQL语句时出现以下报错：（伪分布式环境下500w条数据） 

![image-20201203152855583](https://tva1.sinaimg.cn/large/0081Kckwly1glap95lbd3j31f40lc1d6.jpg)

![image-20201203152512262](https://tva1.sinaimg.cn/large/0081Kckwly1glap5a3gg7j31740eyq57.jpg)

**报错显示**

Error: Java heap space

FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask

### # 原因分析

查资料说是因为内存的原因，由于HQL实际上是被转换成mapreduce的java任务，所以会在数据量比较大的时候，在map/reduce阶段内存不足，所以可以修改hadoop-env.xml, yarn-env.sh, mapred-site.xml配置文件，增大分配的空间

### # 解决方法

```shell
> vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh

# 默认 1000
export HADOOP_HEAPSIZE=4096

> vim $HADOOP_HOME/etc/hadoop/yarn-env.sh

# 默认 1000
YARN_HEAPSIZE=4096
```

只设置了hadoop memory是不work的，这是因为heapsize 是hadoop 自身使用的memory，比如job tracker, task tacker等，属于hadoop 自身，map reduce 任务是hadoop 启动的task，是用户任务，是独立进程，这里设置的也是heapsize只不过是Hadoop自身的内存，task默认的heapsize 小了。所以还需要如下设置用户态进程的内存设置：

```xml
<property>
    <name>mapreduce.map.memory.mb</name>
    <value>1536</value>
</property>

<property>
    <name>mapreduce.map.java.opts</name>
    <value>-Xmx1024M</value>
</property>

<property>
    <name>mapreduce.reduce.memory.mb</name>
    <value>3072</value>
</property>

<property>
    <name>mapreduce.reduce.java.opts</name>
    <value>-Xmx2560M</value>
</property>

<property>
    <name>mapreduce.task.io.sort.mb</name>
    <value>512</value>
</property>

<property>
    <name>mapreduce.task.io.sort.factor</name>
    <value>100</value>
</property>

<property>
    <name>mapreduce.reduce.shuffle.parallelcopies</name>
    <value>50</value>
</property>
```

✌️ 配置完后下面操作的响应速度都变得很快，证明这个方法是work and excellent